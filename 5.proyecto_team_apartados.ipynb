{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2343bfd",
   "metadata": {},
   "source": [
    "### 5. **Análisis de Correlación y Regresión**\n",
    "**Resumen:** Se centra en la identificación de relaciones significativas entre las variables numéricas y el desarrollo de modelos de regresión para hacer predicciones basadas en esas relaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1695ab4-c404-40ab-99c2-8dd3e416eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llegim les dades del dataframe y preparem la columna date correctament\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "df = pd.read_csv(\"avocado.csv\")\n",
    "df_cp = df.copy()\n",
    "df_cp['Date'] = pd.to_datetime(df_cp['Date'])\n",
    "\n",
    "region_classification = {\n",
    "'Albany': 'City',\n",
    "'Atlanta': 'City',\n",
    "'BaltimoreWashington': 'Region',\n",
    "'Boise': 'City',\n",
    "'Boston': 'City',\n",
    "'BuffaloRochester': 'Region',\n",
    "'California': 'GreaterRegion',\n",
    "'Charlotte': 'City',\n",
    "'Chicago': 'City',\n",
    "'CincinnatiDayton': 'Region',\n",
    "'Columbus': 'City',\n",
    "'DallasFtWorth': 'Region',\n",
    "'Denver': 'City',\n",
    "'Detroit': 'City',\n",
    "'GrandRapids': 'City',\n",
    "'GreatLakes': 'GreaterRegion',\n",
    "'HarrisburgScranton': 'Region',\n",
    "'HartfordSpringfield': 'Region',\n",
    "'Houston': 'City',\n",
    "'Indianapolis': 'City',\n",
    "'Jacksonville': 'City',\n",
    "'LasVegas': 'City',\n",
    "'LosAngeles': 'City',\n",
    "'Louisville': 'City',\n",
    "'MiamiFtLauderdale': 'Region',\n",
    "'Midsouth': 'GreaterRegion',\n",
    "'Nashville': 'City',\n",
    "'NewOrleansMobile': 'Region',\n",
    "'NewYork': 'City',\n",
    "'Northeast': 'GreaterRegion',\n",
    "'NorthernNewEngland': 'Region',\n",
    "'Orlando': 'City',\n",
    "'Philadelphia': 'City',\n",
    "'PhoenixTucson': 'Region',\n",
    "'Pittsburgh': 'City',\n",
    "'Plains': 'GreaterRegion',\n",
    "'Portland': 'City',\n",
    "'RaleighGreensboro': 'Region',\n",
    "'RichmondNorfolk': 'Region',\n",
    "'Roanoke': 'City',\n",
    "'Sacramento': 'City',\n",
    "'SanDiego': 'City',\n",
    "'SanFrancisco': 'City',\n",
    "'Seattle': 'City',\n",
    "'SouthCarolina': 'Region',\n",
    "'SouthCentral': 'GreaterRegion',\n",
    "'Southeast': 'GreaterRegion',\n",
    "'Spokane': 'City',\n",
    "'StLouis': 'City',\n",
    "'Syracuse': 'City',\n",
    "'Tampa': 'City',\n",
    "'TotalUS': 'TotalUS',\n",
    "'West': 'GreaterRegion',\n",
    "'WestTexNewMexico': 'Region'\n",
    "}\n",
    "\n",
    "classification_colors = {'City':'green' ,'Region':'yellow' ,'GreaterRegion':'orange', 'State':'red', 'TotalUS': 'blue'}\n",
    "\n",
    "df_cp['region_class']= df_cp['region'].map(region_classification)\n",
    "\n",
    "df_cp = df_cp.rename(columns={df.columns[0]: 'Col_0'}) # Primera columna sin titulo, potencialmente eliminable\n",
    "df_cp = df_cp.rename(columns={'4046': 'Volume_Hass_S'}) # Etiquetas mas descritivas\n",
    "df_cp = df_cp.rename(columns={'4225': 'Volume_Hass_L'})\n",
    "df_cp = df_cp.rename(columns={'4770': 'Volume_Hass_XL'})\n",
    "df_cp_cleaned = df_cp.drop('Col_0', axis=1) # Parecen IDs del 0 al 52. Eliminable. # Col_0 = df_cp['Col_0'].unique()  print(f\"Col_0: {Col_0}\\n\")\n",
    "df_cp_cleaned = df_cp[df_cp.region != 'TotalUS'] # Para seleccionar unicamente las regiones propias , descartamos Total US para la vista gráfica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202ae8bd",
   "metadata": {},
   "source": [
    "## 1. **Matriz de Correlación:** \n",
    "   - **Uso de Datos:** Utiliza las columnas numéricas del DataFrame (p. ej., `AveragePrice`, `Total Volume`, `4046`, `4225`, `4770`, `Total Bags`).\n",
    "   - **Esperado:** \n",
    "     - Importa las librerías necesarias: `import seaborn as sns` y `import matplotlib.pyplot as plt`.\n",
    "     - Calcula la matriz de correlación usando el método `.corr()` del DataFrame.\n",
    "     - Visualiza la matriz utilizando `sns.heatmap()`. \n",
    "     - Anota las correlaciones más significativas y discute su posible impacto en el análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c56f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr_gen= df_cp.copy()\n",
    "\n",
    "df_corr_gen = df_corr_gen[df_corr_gen['region']=='Philadelphia']\n",
    "\n",
    "# df_corr_gen = df_corr_gen[(df_corr_gen['region_class']== 'City') | (df_corr_gen['region_class']== 'Region')]\n",
    "\n",
    "corr_df= df_corr_gen[['AveragePrice', 'Total Volume', 'Total Bags' ,'Volume_Hass_S', 'Volume_Hass_L', 'Volume_Hass_XL']]\n",
    "# Calcular la matriz de correlación\n",
    "corr_matrix = corr_df.corr()\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Matriz de Correlación')\n",
    "plt.show()\n",
    "\n",
    "# Identificar columnas con correlación alta (umbral = 0.8)\n",
    "threshold = 0.8\n",
    "to_drop = []\n",
    "for column in corr_matrix.columns:\n",
    "    if any((corr_matrix[column].abs() > threshold) & (corr_matrix.index != column)):\n",
    "        to_drop.append(column)\n",
    "        \n",
    "print(f\"Variables altamente correlacionadas con otras: {to_drop}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73531acc",
   "metadata": {},
   "source": [
    "\n",
    "## 2. **Análisis de Dispersión entre Variables Clave:** \n",
    "   - **Uso de Datos:** Selecciona variables numéricas de interés como `AveragePrice` y `Total Volume`.\n",
    "   - **Esperado:** \n",
    "     - Importa las librerías necesarias: `import seaborn as sns` y `import matplotlib.pyplot as plt`.\n",
    "     - Crea un gráfico de dispersión con `sns.scatterplot()` para visualizar la relación entre `AveragePrice` y `Total Volume`.\n",
    "     - Añade una línea de regresión utilizando `sns.regplot()` para ilustrar las tendencias.\n",
    "     - Compara el ajuste de una regresión lineal frente a una polinómica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ef2b9-f102-42f5-86d6-a810b4d35c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local = df_cp.copy()\n",
    "df_local= df_local[df_local['type']=='organic']\n",
    "df_local= df_local[df_local['region']=='TotalUS']\n",
    "df_local = df_local[df_local['AveragePrice']==1.0]\n",
    "display(df_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a36419-db3c-4f44-8550-19ed8b4a813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_local = df_cp.copy()\n",
    "# df_local= df_local[df_local['type']=='conventional']\n",
    "\n",
    "# # df_local = df_cp[(df_cp['region']!='TotalUS')&(df_cp['region_class']!='GreaterRegion')].copy()\n",
    "# df_local_USA=df_local[df_local['region_class']=='TotalUS']\n",
    "\n",
    "# fig, ax= plt.subplots(figsize=(10,6))\n",
    "\n",
    "# # sns.scatterplot(data= df_local , x=df_local['Total Volume'], y=df_local['AveragePrice'], alpha= 0.1)\n",
    "# sns.regplot(data= df_local_USA , x=df_local_USA['Total Volume'], y=df_local_USA['AveragePrice'], order=1)#, line=True)\n",
    "# plt.xscale('log')\n",
    "# plt.grid()\n",
    "# plt.title('Conventional')\n",
    "# plt.figure()\n",
    "\n",
    "df_local = df_cp.copy()\n",
    "df_local= df_local[df_local['type']=='organic']\n",
    "\n",
    "# df_local = df_cp[(df_cp['region']!='TotalUS')&(df_cp['region_class']!='GreaterRegion')].copy()\n",
    "df_local_USA=df_local[df_local['region_class']=='TotalUS']\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(10,6))\n",
    "\n",
    "# sns.scatterplot(data= df_local , x=df_local['Total Volume'], y=df_local['AveragePrice'], alpha= 0.1)\n",
    "sns.regplot(data= df_local_USA , x=df_local_USA['Total Volume'], y=df_local_USA['AveragePrice'], order=1)#, line=True)\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "plt.title('TotalUS')\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5cf48e-5f88-4c8c-ac5e-4b85f39a68e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local = df_cp.copy()\n",
    "df_local= df_local[df_local['type']=='organic']\n",
    "\n",
    "# df_local = df_cp[(df_cp['region']!='TotalUS')&(df_cp['region_class']!='GreaterRegion')].copy()\n",
    "df_local_USA=df_local[df_local['region_class']=='TotalUS']\n",
    "df_local_USA=df_local_USA[df_local_USA['AveragePrice']>1.1]\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(10,6))\n",
    "\n",
    "# sns.scatterplot(data= df_local , x=df_local['Total Volume'], y=df_local['AveragePrice'], alpha= 0.1)\n",
    "sns.regplot(data= df_local_USA , x=df_local_USA['Total Volume'], y=df_local_USA['AveragePrice'], order=1)#, line=True)\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "plt.title('TotalUS Organic')\n",
    "plt.figure()\n",
    "\n",
    "# df_local = df_cp[(df_cp['region']!='TotalUS')&(df_cp['region_class']!='GreaterRegion')].copy()\n",
    "df_local_region=df_local[df_local['region_class']=='City']\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(10,6))\n",
    "\n",
    "# sns.scatterplot(data= df_local , x=df_local['Total Volume'], y=df_local['AveragePrice'], alpha= 0.1)\n",
    "sns.regplot(data= df_local_region , x=df_local_region['Total Volume'], y=df_local_region['AveragePrice'], order=1)#, line=True)\n",
    "plt.xscale('log')\n",
    "plt.title('City Organic')\n",
    "plt.grid()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffaa3e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local = df_cp.copy()\n",
    "df_local= df_local[df_local['type']=='organic']\n",
    "\n",
    "# df_local = df_cp[(df_cp['region']!='TotalUS')&(df_cp['region_class']!='GreaterRegion')].copy()\n",
    "df_local_USA=df_local[df_local['region_class']=='TotalUS']\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(10,6))\n",
    "\n",
    "# sns.scatterplot(data= df_local , x=df_local['Total Volume'], y=df_local['AveragePrice'], alpha= 0.1)\n",
    "sns.regplot(data= df_local_USA , x=df_local_USA['Total Volume'], y=df_local_USA['AveragePrice'], order=1)#, line=True)\n",
    "plt.xscale('log')\n",
    "plt.grid()\n",
    "plt.title('TotalUS')\n",
    "plt.figure()\n",
    "\n",
    "# df_local = df_cp[(df_cp['region']!='TotalUS')&(df_cp['region_class']!='GreaterRegion')].copy()\n",
    "df_local_region=df_local[df_local['region_class']=='City']\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(10,6))\n",
    "\n",
    "# sns.scatterplot(data= df_local , x=df_local['Total Volume'], y=df_local['AveragePrice'], alpha= 0.1)\n",
    "sns.regplot(data= df_local_region , x=df_local_region['Total Volume'], y=df_local_region['AveragePrice'], order=1)#, line=True)\n",
    "plt.xscale('log')\n",
    "plt.title('City')\n",
    "plt.grid()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed23d254",
   "metadata": {},
   "source": [
    "3. **Predicciones Mensuales Usando Datos Trimestrales:**\n",
    "   - **Uso de Datos:** Agrupa datos por trimestres y segmenta en meses utilizando `Date`, `AveragePrice`, y `Total Volume`.\n",
    "   - **Esperado:** \n",
    "     - Convierte la columna `Date` a tipo datetime si es necesario.\n",
    "     - Agrupa los datos por trimestre y calcula el promedio de `AveragePrice` y `Total Volume`.\n",
    "     - Utiliza los datos de los primeros 2 meses de un trimestre para predecir el precio del tercer mes.\n",
    "     - Compara los resultados de las predicciones con los precios reales.\n",
    "     - Evalúa la precisión de tus predicciones utilizando métricas como R² y RMSE.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4233647f-070e-4ba6-b58b-3766276f33e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2513902",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_local= df_cp.copy()\n",
    "\n",
    "# df_local= df_local[df_local['region']=='West']\n",
    "# df_local= df_local[df_local['type']=='conventional']\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "df_local['Day'] = df_local['Date'].dt.to_period('d')#.weekday()\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Week'] = df_local['Date'].dt.to_period('W')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "\n",
    "df_fit = df_local[df_local['Quarter Month']!=3 ]\n",
    "df_check = df_local[df_local['Quarter Month']==3 ]\n",
    "\n",
    "group_fit = df_fit.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "group_fit['Quarter_n']=group_fit['Quarter'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "# group_fit['Total Volume'] = np.log(group_fit['Total Volume'])\n",
    "\n",
    "group_check = df_check.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "group_check['Quarter_n']=group_fit['Quarter'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "# group_check['Total Volume'] = np.log(group_check['Total Volume'])\n",
    "\n",
    "# group_fit.info()\n",
    "\n",
    "# df_local\n",
    "\n",
    "# group_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f109dbd-5a23-46c6-897f-aaa961ff2c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# Importar las bibliotecas necesarias para el modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# group_fit = df_fit.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "X_train= group_fit['Total Volume'].to_frame()\n",
    "y_train= group_fit['AveragePrice']\n",
    "\n",
    "# group_check = df_fit.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "X_test= group_check['Total Volume'].to_frame()\n",
    "y_test= group_check['AveragePrice']\n",
    "\n",
    "# ##########################################\n",
    "# np.random.seed(42)\n",
    "# X1 = np.random.rand(100)\n",
    "# data = pd.DataFrame({\n",
    "#     'X1': X1,\n",
    "#     'X2': (X1 * 0.4) + 0.2,  # Alta correlación con X1\n",
    "#     'X3': np.random.rand(100),               # Variable independiente\n",
    "#     'X4': np.random.rand(100),               # Variable independiente\n",
    "#     'Y': np.random.rand(100)                 # Variable objetivo\n",
    "# })\n",
    "\n",
    "# data_cleaned = data.drop(columns=['X2'])\n",
    "\n",
    "# X = data_cleaned.drop(columns='Y')\n",
    "# y = data_cleaned['Y']\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# print(X_train)\n",
    "##########################################\n",
    "# Aplicar un modelo de regresión lineal para interpolar\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predecir los valores en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred[:10]\n",
    "})\n",
    "\n",
    "# Calcular el error porcentual\n",
    "comparison_df['Error Porcentual'] = ((comparison_df['Valor Real'] - comparison_df['Valor Predicho']) / comparison_df['Valor Real']) * 100\n",
    "\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real:\\n\", comparison_df)\n",
    "\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo: {mse:.4f}\")\n",
    "\n",
    "# Calcular el valor R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nValor R² del modelo: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0eb2d0",
   "metadata": {},
   "source": [
    "## 4. **Predicciones Trimestrales:**\n",
    "   - **Uso de Datos:** Agrupa los datos en trimestres usando solo variables numéricas.\n",
    "   - **Esperado:** \n",
    "     - Agrupa los datos por trimestres usando `pd.Grouper()` con `freq='Q'` para obtener promedios.\n",
    "     - Usa los datos de 1 o 2 trimestres anteriores para predecir el siguiente trimestre ajustando modelos de regresión lineal y polinómica.\n",
    "     - Compara los resultados de las predicciones con los precios reales.\n",
    "     - Evalúa la precisión de tus predicciones utilizando métricas como R² y RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae4f5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import avocado_manager as av\n",
    "av.init()\n",
    "df_cp = av.df(\"df_cp\")\n",
    "print(df_cp.info())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "\n",
    "df_local= df_cp.copy()\n",
    "\n",
    "df_local= df_local[df_local['region']=='West']\n",
    "df_local= df_local[df_local['type']=='conventional']\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "#df_local['Day'] = df_local['Date'].dt.to_period('d')#.weekday()\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Week'] = df_local['Date'].dt.to_period('W')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "\n",
    "df_local['n_Quarter'] = df_local['Month'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "display(df_local[['Month','Quarter','Week','Quarter Month']])\n",
    "\n",
    "df_year = df_local[df_local['year']==2016]\n",
    "\n",
    "\n",
    "\n",
    "########\n",
    "# !!!!!!!\n",
    "## TODO: Xavi random de l'ordre de les dades de train\n",
    "# !!!!!!!\n",
    "\n",
    "df_train = df_year[df_year['n_Quarter'].isin([1,2,3]) ]\n",
    "df_test= df_year[df_year['n_Quarter']==4 ]\n",
    "# display(df_local)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train= df_train['Total Volume'].to_frame()\n",
    "y_train= df_train['AveragePrice']\n",
    "\n",
    "X_test= df_test['Total Volume'].to_frame()\n",
    "y_test= df_test['AveragePrice']\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar un modelo de regresión lineal para interpolar\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "poly_model.fit(X_poly, y_train)\n",
    "y_pred_poly_train = poly_model.predict(X_poly)\n",
    "\n",
    "X_test_poly= poly_features.fit_transform(X_test)\n",
    "y_pred_poly_test = poly_model.predict(X_test_poly)\n",
    "\n",
    "r2_poly_test = r2_score(y_test, y_pred_poly_test)\n",
    "rmse_poly_test = root_mean_squared_error(y_test, y_pred_poly_test)\n",
    "r2_poly_train = r2_score(y_train, y_pred_poly_train)\n",
    "rmse_poly_train = root_mean_squared_error(y_train, y_pred_poly_train)\n",
    "\n",
    "#     \"coeficientes\": poly_model.coef_}\n",
    "\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real de train\n",
    "comparison_df_train = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred_poly_train[0:10]\n",
    "})\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real de test\n",
    "comparison_df_tst = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred_poly_test[0:10]\n",
    "})\n",
    "\n",
    "\n",
    "# Calcular el error porcentual\n",
    "comparison_df_train['Error Porcentual'] = ((comparison_df_train['Valor Real'] - comparison_df_train['Valor Predicho']) / comparison_df_train['Valor Real']) * 100\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real de train:\\n\", comparison_df_train)\n",
    "\n",
    "comparison_df_tst['Error Porcentual'] = ((comparison_df_tst['Valor Real'] - comparison_df_tst['Valor Predicho']) / comparison_df_tst['Valor Real']) * 100\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real de test:\\n\", comparison_df_tst)\n",
    "\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo train : {rmse_poly_train:.6f}\")\n",
    "# Calcular el valor R²\n",
    "print(f\"Valor R² del modelo train: {r2_poly_train:.6f}\")\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo test: {rmse_poly_test:.6f}\")\n",
    "# Calcular el valor R²\n",
    "print(f\"Valor R² del modelo test: {r2_poly_test:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f48a23",
   "metadata": {},
   "source": [
    "## 5. **Predicciones Anuales:**\n",
    "   - **Uso de Datos:** Agrupa los datos en años, utilizando únicamente columnas numéricas.\n",
    "   - **Esperado:** \n",
    "     - Agrupa los datos por año utilizando `pd.Grouper()` con `freq='Y'`.\n",
    "     - Usa los datos de 1 o 2 años anteriores para predecir el siguiente año ajustando modelos de regresión lineal y polinómica.\n",
    "     - Evalúa la precisión de tus predicciones utilizando métricas como R² y RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c94a5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "df_local= df_cp.copy()\n",
    "\n",
    "df_local= df_local[df_local['region']=='West']\n",
    "# df_local= df_local[df_local['type']=='conventional']\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "df_local['Day'] = df_local['Date'].dt.to_period('d')#.weekday()\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Week'] = df_local['Date'].dt.to_period('W')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "df_local['n_Quarter'] = df_local['Month'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "\n",
    "# df_year = df_local[df_local['year']==2016]\n",
    "\n",
    "########\n",
    "df_train = df_local[df_local['year'].isin([2015,2016]) ]\n",
    "df_test= df_local[df_local['year']==2017 ]\n",
    "# display(df_train)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train= df_train['Total Volume'].to_frame()\n",
    "y_train= df_train['AveragePrice']\n",
    "\n",
    "X_test= df_test['Total Volume'].to_frame()\n",
    "y_test= df_test['AveragePrice']\n",
    "\n",
    "###########\n",
    "# Aplicar un modelo de regresión lineal para interpolar\n",
    "poly_features = PolynomialFeatures(degree=1)\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "poly_model.fit(X_poly, y_train)\n",
    "y_pred_poly_train = poly_model.predict(X_poly)\n",
    "\n",
    "X_test_poly= poly_features.fit_transform(X_test)\n",
    "y_pred_poly_test = poly_model.predict(X_test_poly)\n",
    "\n",
    "\n",
    "r2_poly_train = r2_score(y_test, y_pred_poly_test)\n",
    "rmse_poly_train = mean_squared_error(y_test, y_pred_poly_test)\n",
    "\n",
    "#     \"coeficientes\": poly_model.coef_}\n",
    "\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred_poly_test[:10]\n",
    "})\n",
    "\n",
    "# Calcular el error porcentual\n",
    "comparison_df['Error Porcentual'] = ((comparison_df['Valor Real'] - comparison_df['Valor Predicho']) / comparison_df['Valor Real']) * 100\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real:\\n\", comparison_df)\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo: {rmse_poly_train:.4f}\")\n",
    "\n",
    "# Calcular el valor R²\n",
    "print(f\"\\nValor R² del modelo: {r2_poly_train:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f2e78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "import avocado_manager as av\n",
    "av.init()\n",
    "df_cp = av.df(\"df_cp\")\n",
    "print(df_cp.info())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error, r2_score, root_mean_squared_error\n",
    "\n",
    "\n",
    "df_local= df_cp.copy()\n",
    "\n",
    "df_local= df_local[df_local['region']=='West']\n",
    "#df_local= df_local[df_local['type']=='conventional']\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "#df_local['Day'] = df_local['Date'].dt.to_period('d')#.weekday()\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Week'] = df_local['Date'].dt.to_period('W')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "\n",
    "df_local['n_Quarter'] = df_local['Month'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "display(df_local[['Month','Quarter','Week','Quarter Month']])\n",
    "\n",
    "# df_year = df_local[df_local['year']==2016]\n",
    "\n",
    "\n",
    "########\n",
    "# !!!!!!!\n",
    "## TODO: Xavi random de l'ordre de les dades de train\n",
    "# !!!!!!!\n",
    "\n",
    "df_train = df_local[df_local['year'].isin([2015,2016]) ]\n",
    "df_test= df_local[df_local['year']==2017 ]\n",
    "# display(df_local)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train= df_train['Total Volume'].to_frame()\n",
    "y_train= df_train['AveragePrice']\n",
    "\n",
    "X_test= df_test['Total Volume'].to_frame()\n",
    "y_test= df_test['AveragePrice']\n",
    "\n",
    "###########\n",
    "\n",
    "\n",
    "\n",
    "# Aplicar un modelo de regresión lineal para interpolar\n",
    "poly_features = PolynomialFeatures(degree=1)\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "poly_model.fit(X_poly, y_train)\n",
    "y_pred_poly_train = poly_model.predict(X_poly)\n",
    "\n",
    "X_test_poly= poly_features.fit_transform(X_test)\n",
    "y_pred_poly_test = poly_model.predict(X_test_poly)\n",
    "\n",
    "r2_poly_test = r2_score(y_test, y_pred_poly_test)\n",
    "rmse_poly_test = root_mean_squared_error(y_test, y_pred_poly_test)\n",
    "r2_poly_train = r2_score(y_train, y_pred_poly_train)\n",
    "rmse_poly_train = root_mean_squared_error(y_train, y_pred_poly_train)\n",
    "\n",
    "#     \"coeficientes\": poly_model.coef_}\n",
    "\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real de train\n",
    "comparison_df_train = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred_poly_train[0:10]\n",
    "})\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real de test\n",
    "comparison_df_tst = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred_poly_test[0:10]\n",
    "})\n",
    "\n",
    "\n",
    "# Calcular el error porcentual\n",
    "comparison_df_train['Error Porcentual'] = ((comparison_df_train['Valor Real'] - comparison_df_train['Valor Predicho']) / comparison_df_train['Valor Real']) * 100\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real de train:\\n\", comparison_df_train)\n",
    "\n",
    "comparison_df_tst['Error Porcentual'] = ((comparison_df_tst['Valor Real'] - comparison_df_tst['Valor Predicho']) / comparison_df_tst['Valor Real']) * 100\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real de test:\\n\", comparison_df_tst)\n",
    "\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo train : {rmse_poly_train:.6f}\")\n",
    "# Calcular el valor R²\n",
    "print(f\"Valor R² del modelo train: {r2_poly_train:.6f}\")\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo test: {rmse_poly_test:.6f}\")\n",
    "# Calcular el valor R²\n",
    "print(f\"Valor R² del modelo test: {r2_poly_test:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147db94a",
   "metadata": {},
   "source": [
    "## 6. **Desarrollo de Modelos de Regresión Múltiple:** \n",
    "   - **Uso de Datos:** Selecciona varias variables numéricas como `Total Volume`, `4046`, `4225`, `4770`, y `Total Bags` para predecir `AveragePrice`.\n",
    "   - **Esperado:** \n",
    "     - Define las variables independientes (X) y dependientes (y).\n",
    "     - Ajusta modelos de regresión múltiple.\n",
    "     - Compara su rendimiento utilizando métricas como R² y RMSE y discute las implicaciones de los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b993478",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_local = df_cp.copy()\n",
    "\n",
    "df_local=df_local[df_local['region']=='West']\n",
    "# df_local=df_local[df_local['type']=='conventional']\n",
    "\n",
    "bool_org= {'organic':1, 'conventional':0}\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "df_local['n_Quarter'] = df_local['Month'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "df_local['type_Bool'] = df_local['type'].map(bool_org)\n",
    "\n",
    "display(df_local)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f4a1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_local = df_cp.copy()\n",
    "\n",
    "df_local=df_local[df_local['region']=='West']\n",
    "# df_local=df_local[df_local['type']=='conventional']\n",
    "\n",
    "bool_org= {'organic':1, 'conventional':0}\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "df_local['n_Quarter'] = df_local['Month'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "df_local['type_Bool'] = df_local['type'].map(bool_org)\n",
    "\n",
    "# Estandaritzar\n",
    "df_local['Standard Volume'] = (df_local['Total Volume'] - df_local['Total Volume'].mean()) /df_local['Total Volume'].std()\n",
    "df_local['ST_Volume_Hass_S'] = (df_local['Volume_Hass_S'] - df_local['Volume_Hass_S'].mean()) /df_local['Volume_Hass_S'].std()\n",
    "df_local['ST_Volume_Hass_L'] = (df_local['Volume_Hass_L'] - df_local['Volume_Hass_L'].mean()) /df_local['Volume_Hass_L'].std()\n",
    "df_local['ST_Volume_Hass_XL'] = (df_local['Volume_Hass_XL'] - df_local['Volume_Hass_XL'].mean()) /df_local['Volume_Hass_XL'].std()\n",
    "df_local['Standard Bags'] = (df_local['Total Bags'] - df_local['Total Bags'].mean()) /df_local['Total Bags'].std()\n",
    "# display(df_local)\n",
    "\n",
    "#### versio polinomica Victor i Cesc per poder veure la diferencia amb la polinomica\n",
    "# Aplicar un modelo de regresión lineal para interpolar\n",
    "#poly_features = PolynomialFeatures(degree=1)\n",
    "#X_poly = poly_features.fit_transform(X_train)\n",
    "\n",
    "#poly_model = LinearRegression()\n",
    "#poly_model.fit(X_poly, y_train)\n",
    "# Predecir los valores en el conjunto de prueba\n",
    "#y_pred_poly_train = poly_model.predict(X_poly)\n",
    "\n",
    "#X_test_poly= poly_features.fit_transform(X_test)\n",
    "#y_pred_poly_test = poly_model.predict(X_test_poly)\n",
    "#### versio polinomica\n",
    "\n",
    "\n",
    "Variables = ['Standard Volume', 'ST_Volume_Hass_S', 'ST_Volume_Hass_L', 'ST_Volume_Hass_XL', 'Standard Bags', 'n_Quarter', 'year', 'type_Bool']\n",
    "# group_fit = df_fit.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "X= df_local[Variables]\n",
    "Y= df_local['AveragePrice']#.to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test =  train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# group_check = df_fit.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "# X_test= df_year.loc[2:3,'Total Volume'].to_frame()\n",
    "# y_test= df_year.loc[2:3,'AveragePrice']#.to_frame()\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "# Predecir los valores en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred[:10]\n",
    "})\n",
    "\n",
    "##  TODO: Xavi: Aixo es AveragePrice, correcte ? i no esta estandaritzat, correcte ?\n",
    "display(y_test)\n",
    "\n",
    "# Calcular el error porcentual\n",
    "comparison_df['Error Porcentual'] = ((comparison_df['Valor Real'] - comparison_df['Valor Predicho']) / comparison_df['Valor Real']) * 100\n",
    "\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real:\\n\", comparison_df)\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo: {mse:.4f}\")\n",
    "for i in range(0, len(Variables)):    \n",
    "    print(f'El coeficiente {Variables[i]}\\t \\t: {model.coef_[i]}')\n",
    "\n",
    "# Calcular el valor R²\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"\\nValor R² del modelo: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448180ca",
   "metadata": {},
   "source": [
    "7. **Análisis de Coeficientes de Regresión Múltiple:**\n",
    "   - **Uso de Datos:** Examina los coeficientes de los modelos de regresión múltiple ajustados.\n",
    "   - **Esperado:** \n",
    "     - Extrae los coeficientes del modelo ajustado.\n",
    "     - Interpreta los coeficientes para entender el impacto de cada variable numérica en `AveragePrice`.\n",
    "     - Comenta sobre las variables más significativas y su relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb37a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(Variables)):\n",
    "    \n",
    "    print(f'El coeficiente {Variables[i]}\\t \\t: {model.coef_[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2cbb59c",
   "metadata": {},
   "source": [
    "8. **Modelos de Regresión para Diferenciar Volúmenes de Ventas:**\n",
    "   - **Uso de Datos:** Usa `AveragePrice`, `Total Volume`, `4046`, `4225`, y `4770`.\n",
    "   - **Esperado:** \n",
    "     - Ajusta modelos de regresión para analizar cómo los diferentes volúmenes de ventas afectan `AveragePrice`.\n",
    "     - Compara los resultados de regresión lineal y polinómica.\n",
    "     - Presenta las conclusiones de tus análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed7a30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "df_local = df_cp.copy()\n",
    "\n",
    "df_local=df_local[df_local['region']=='West']\n",
    "# df_local=df_local[df_local['type']=='conventional']\n",
    "\n",
    "bool_org= {'organic':1, 'conventional':0}\n",
    "\n",
    "df_local['Month'] = df_local['Date'].dt.to_period('M')\n",
    "df_local['Quarter'] = df_local['Date'].dt.to_period('Q')\n",
    "df_local['Quarter Month'] = df_local['Month'].map(lambda x: (x.month - 1) % 3 + 1 )\n",
    "df_local['n_Quarter'] = df_local['Month'].map(lambda date: (date.month - 1) // 3 + 1)\n",
    "df_local['type_Bool'] = df_local['type'].map(bool_org)\n",
    "\n",
    "df_local['Standard Volume'] = (df_local['Total Volume'] - df_local['Total Volume'].mean()) /df_local['Total Volume'].std()\n",
    "df_local['ST_Volume_Hass_S'] = (df_local['Volume_Hass_S'] - df_local['Volume_Hass_S'].mean()) /df_local['Volume_Hass_S'].std()\n",
    "df_local['ST_Volume_Hass_L'] = (df_local['Volume_Hass_L'] - df_local['Volume_Hass_L'].mean()) /df_local['Volume_Hass_L'].std()\n",
    "df_local['ST_Volume_Hass_XL'] = (df_local['Volume_Hass_XL'] - df_local['Volume_Hass_XL'].mean()) /df_local['Volume_Hass_XL'].std()\n",
    "df_local['Standard Bags'] = (df_local['Total Bags'] - df_local['Total Bags'].mean()) /df_local['Total Bags'].std()\n",
    "\n",
    "\n",
    "# display(df_local)\n",
    "\n",
    "Variables = ['Standard Volume', 'ST_Volume_Hass_S', 'ST_Volume_Hass_L', 'ST_Volume_Hass_XL', 'Standard Bags', 'n_Quarter', 'year', 'type_Bool']\n",
    "# group_fit = df_fit.groupby('Quarter').agg({'AveragePrice':'mean', 'Total Volume':'mean' }).reset_index()\n",
    "X= df_local[Variables]\n",
    "Y= df_local['AveragePrice']#.to_frame()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "###########\n",
    "# Aplicar un modelo de regresión lineal para interpolar\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "poly_model = LinearRegression()\n",
    "\n",
    "X_poly = poly_features.fit_transform(X_train)\n",
    "poly_model.fit(X_poly, y_train)\n",
    "y_pred_poly_train = poly_model.predict(X_poly)\n",
    "\n",
    "X_test_poly= poly_features.fit_transform(X_test)\n",
    "y_pred_poly_test = poly_model.predict(X_test_poly)\n",
    "\n",
    "# Comparar los primeros 10 valores entre el valor predicho y el valor real\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Valor Real': y_test.head(10).values,\n",
    "    'Valor Predicho': y_pred_poly_test[:10]\n",
    "})\n",
    "\n",
    "# Calcular el error porcentual\n",
    "comparison_df['Error Porcentual'] = ((comparison_df['Valor Real'] - comparison_df['Valor Predicho']) / comparison_df['Valor Real']) * 100\n",
    "\n",
    "print(\"\\nComparación de los primeros 10 valores entre el valor predicho y el valor real:\\n\", comparison_df)\n",
    "\n",
    "\n",
    "# Calcular el error cuadrático medio (MSE) para evaluar el modelo\n",
    "mse = mean_squared_error(y_test, y_pred_poly_test)\n",
    "print(f\"\\nError cuadrático medio (MSE) del modelo: {mse:.4f}\")\n",
    "\n",
    "\n",
    "for i in range(0, len(Variables)):\n",
    "    \n",
    "    print(f'El coeficiente {Variables[i]}\\t \\t: {model.coef_[i]}')\n",
    "\n",
    "# Calcular el valor R²\n",
    "r2 = r2_score(y_test, y_pred_poly_test)\n",
    "print(f\"\\nValor R² del modelo: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f758db11",
   "metadata": {},
   "source": [
    "9. **Análisis de la Influencia de las Ventas Totales en el Precio Promedio:**\n",
    "   - **Uso de Datos:** Usa `Total Volume`, `AveragePrice`, y `Total Bags`.\n",
    "   - **Esperado:** \n",
    "     - Ajusta un modelo de regresión lineal y polinómica para ver cómo varía `AveragePrice` en función del volumen total de ventas.\n",
    "     - Evalúa la significancia de los coeficientes y discute su relevancia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdd909e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ad8ddb6",
   "metadata": {},
   "source": [
    "10. **Regresión para Predecir el Precio Promedio Según el Volumen de Aguacates por Tipo:**\n",
    "    - **Uso de Datos:** Usa `AveragePrice`, `4046`, `4225`, `4770`, y `Total Volume`.\n",
    "    - **Esperado:** \n",
    "      - Ajusta modelos de regresión lineal y polinómica.\n",
    "      - Evalúa la efectividad de ambos modelos utilizando métricas como R² y RMSE.\n",
    "      - Discute cuál modelo ofrece mejores predicciones y por qué, basándote en los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd83ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "df = pd.read_csv(\"avocado.csv\")\n",
    "df_cp = df.copy()\n",
    "df_cp['Date'] = pd.to_datetime(df_cp['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204fb91c-e981-4046-8bca-885214136f38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "usr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
